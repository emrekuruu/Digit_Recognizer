{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-07-02T16:20:45.994076Z","iopub.status.busy":"2023-07-02T16:20:45.993678Z","iopub.status.idle":"2023-07-02T16:20:47.209059Z","shell.execute_reply":"2023-07-02T16:20:47.207800Z","shell.execute_reply.started":"2023-07-02T16:20:45.994047Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /home/emre2020/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import nltk\n","from gensim.models import Word2Vec\n","nltk.download('punkt')\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T16:10:41.563228Z","iopub.status.busy":"2023-07-02T16:10:41.562042Z","iopub.status.idle":"2023-07-02T16:10:42.351212Z","shell.execute_reply":"2023-07-02T16:10:42.350086Z","shell.execute_reply.started":"2023-07-02T16:10:41.563189Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentiment</th>\n","      <th>review</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>\"With all this stuff going down at the moment ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>\"The film starts with a manager (Nicholas Bell...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>\"It must be assumed that those who praised thi...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   sentiment                                             review\n","0          1  \"With all this stuff going down at the moment ...\n","1          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n","2          0  \"The film starts with a manager (Nicholas Bell...\n","3          0  \"It must be assumed that those who praised thi...\n","4          1  \"Superbly trashy and wondrously unpretentious ..."]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["train=pd.read_csv(\"labeledTrainData.tsv.zip\", header=0, \\\n","                    delimiter=\"\\t\", quoting=3)\n","train=train.drop(['id'],axis=1)\n","train.head()"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["50000"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["train.size"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T16:23:06.338537Z","iopub.status.busy":"2023-07-02T16:23:06.338067Z","iopub.status.idle":"2023-07-02T16:23:06.345753Z","shell.execute_reply":"2023-07-02T16:23:06.344757Z","shell.execute_reply.started":"2023-07-02T16:23:06.338491Z"},"trusted":true},"outputs":[],"source":["def filter(sentence):\n","    result = [word.lower() for word in nltk.word_tokenize(sentence) if word.isalnum()]\n","    return result"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T16:23:07.745537Z","iopub.status.busy":"2023-07-02T16:23:07.745133Z","iopub.status.idle":"2023-07-02T16:23:07.751610Z","shell.execute_reply":"2023-07-02T16:23:07.750400Z","shell.execute_reply.started":"2023-07-02T16:23:07.745506Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['hello', 'buddy']\n"]}],"source":["example = \"Hello, Buddy.\"\n","print(filter(example))"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T16:23:45.370158Z","iopub.status.busy":"2023-07-02T16:23:45.369734Z"},"trusted":true},"outputs":[],"source":["train[\"review\"] = train[\"review\"].apply(filter)"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[],"source":["from gensim.models import KeyedVectors"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# Load vectors directly from the file\n","word2_vec = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def word2_vec_func(sentence):\n","    \n","    result = [word2_vec[word] for word in sentence if word in word2_vec]\n","\n","    return result"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["train[\"review\"] = train[\"review\"].apply(word2_vec_func)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Split your data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(train['review'], train['sentiment'], test_size=0.2)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.autograd import Variable"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["class MyModel(nn.Module):\n","\n","    def __init__(self, embedding_dim, hidden_dim, output_dim, n_layers, \n","                 bidirectional, dropout):\n","        super(MyModel,self).__init__()\n","\n","        self.rnn = nn.LSTM(embedding_dim, \n","                           hidden_dim, \n","                           num_layers=n_layers, \n","                           bidirectional=bidirectional, \n","                           dropout=dropout)\n","        \n","        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","\n","        self.sigmoid = nn.Sigmoid()\n","\n","        \n","    def forward(self, text):\n","        _, (hidden, _) = self.rnn(text)\n","        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n","        return self.sigmoid(self.fc(hidden.squeeze(0)))\n"," "]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["MyModel(\n","  (rnn): LSTM(300, 256, num_layers=2, dropout=0.5, bidirectional=True)\n","  (fc): Linear(in_features=512, out_features=1, bias=True)\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (sigmoid): Sigmoid()\n",")"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["EMBEDDING_DIM = 300\n","HIDDEN_DIM = 256\n","OUTPUT_DIM = 1\n","N_LAYERS = 2\n","BIDIRECTIONAL = True\n","DROPOUT = 0.5\n","\n","model = MyModel(EMBEDDING_DIM, \n","            HIDDEN_DIM, \n","            OUTPUT_DIM, \n","            N_LAYERS, \n","            BIDIRECTIONAL, \n","            DROPOUT)\n","model"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# Loss and optimizer\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.003)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["def acc(base,pred):\n","    correct = torch.eq(base,pred).sum().item()\n","    result = (correct/len(pred))*100\n","    return result"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["def collate_fn(batch):\n","    labels = torch.Tensor([item[1] for item in batch])\n","    sequences = [torch.FloatTensor(item[0]) for item in batch]\n","    lengths = torch.LongTensor([len(seq) for seq in sequences])\n","\n","    # Pad the sequences\n","    sequences = nn.utils.rnn.pad_sequence(sequences, batch_first=True)\n","\n","    return sequences, lengths, labels\n","\n","# Create DataLoader\n","train_data = list(zip(X_train, y_train))\n","train_loader = DataLoader(train_data, batch_size=32, shuffle=True, collate_fn=collate_fn)\n","\n","val_data = list(zip(X_test,y_test))\n","valid_loader = DataLoader(val_data,batch_size=32, shuffle=True,collate_fn=collate_fn)"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0 , Training Loss: 0.1696 Training Accuracy:  93.75\n","Epoch 0, Validation Loss: 0.2358, Validation Accuracy: 90.5454\n","Epoch 1 , Training Loss: 0.1074 Training Accuracy:  93.75\n","Epoch 1, Validation Loss: 0.2449, Validation Accuracy: 90.2667\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = model.to(device)\n","criterion = criterion.to(device)\n","\n","# Assuming we have a validation data loader: valid_loader\n","for epoch in range(10):  # assuming 10 epochs\n","    model.train()\n","    for i, (sequences, lengths, labels) in enumerate(train_loader):\n","        # Convert tensors to device\n","        sequences = sequences.to(device)\n","        labels = labels.to(device)\n","\n","        sequences = pack_padded_sequence(sequences, lengths, batch_first=True, enforce_sorted=False)\n","        outputs = model(sequences).squeeze()\n","        \n","        loss = criterion(outputs, labels)\n","        accuracy = acc(labels, torch.round(outputs).detach())\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","    print (f\"Epoch {epoch} , Training Loss: {loss:.4f} Training Accuracy:  {accuracy}\")\n","\n","    model.eval()\n","    total_val_loss = 0\n","    total_val_acc = 0\n","\n","    # Evaluation with the validation data\n","    with torch.inference_mode():\n","        for i, (sequences, lengths, labels) in enumerate(valid_loader):\n","            sequences = sequences.to(device)\n","            labels = labels.to(device)\n","            \n","            sequences = pack_padded_sequence(sequences, lengths, batch_first=True, enforce_sorted=False)\n","            outputs = model(sequences).squeeze()\n","            total_val_loss += criterion(outputs, labels).item()\n","            total_val_acc += acc(labels, torch.round(outputs).detach())\n","            \n","    print(f\"Epoch {epoch}, Validation Loss: {total_val_loss/len(valid_loader):.4f}, Validation Accuracy: {total_val_acc/len(valid_loader):.4f}\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["example = \"I AM IN LOVE WİTH İT\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["vector = word2_vec_func(filter(example))\n","vector"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Convert the example to a word vector using `word2_vec_func`\n","vector = word2_vec_func(example)\n","\n","# Create a tensor from the word vector\n","input_tensor = torch.tensor(vector)\n","\n","# Add an extra dimension to match the batch size (assuming batch size of 1)\n","input_tensor = input_tensor.unsqueeze(0)\n","\n","# Move the tensor to the appropriate device\n","input_tensor = input_tensor.to(device)\n","\n","# Get the lengths of the sequences (in this case, the single example)\n","lengths = torch.tensor([input_tensor.size(1)])\n","\n","# Pack the sequence using `pack_padded_sequence`\n","packed_sequence = pack_padded_sequence(input_tensor, lengths, batch_first=True)\n","\n","# Pass the packed sequence through your model\n","output = model(packed_sequence)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Apply sigmoid activation function\n","probabilities = torch.sigmoid(output)\n","\n","# Set a threshold to determine the class\n","threshold = 0.5\n","predictions = (probabilities > threshold).int()\n","\n","# Convert predictions to the desired format (positive/negative or 1/0)\n","class_labels = ['negative', 'positive']\n","predicted_class = class_labels[predictions.item()]\n","\n","print(\"Predicted class:\", predicted_class)\n","probabilities"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":4}
